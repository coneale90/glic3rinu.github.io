# Lessons learned from CommunityLab

1. Change your mindset, think big
"You don't have a bunch of slivers, you have a distributed system"
* Create large slices to compensate for offline nodes and other failures
* Automate *everything*, you don't want to manually login into any sliver


2. Make your experiments idempotent
Nodes come and go, you can not assume all your slivers being on the same state.
Design experiments in such a way that can run on both, fresh and already deployed nodes.


3. Use concurrency for experiment deployment and for collecting the results
You *really* don't want to sequentially wait for half of your slivers timing out the SSH connection.
Use scripting languages like Bash. They usually integrate process management into the language itself. Just imagine how the following will look like if written in a language like Java and its threading library:

    cat sliver-mgmt-ip.list | while read IP; do
        { 
          scp -o stricthostkeychecking=no experiment.sh root@[$IP]: &&
          ssh root@$IP "nohup bash experiment.sh" ;
        } &
    done


4. CONFINE REST API doesn't love you too much
It's a node-oriented API, not researcher-oriented. Some *essential* information for your experiments may be cumbersome to obtain.
This snippet can be handy if you want to get all the mgmt IPs of your slivers and be able to start your experiment.

    SLICE_ID = 249
    
    # API calls
    # Requires "pip install confine-orm"
    from orm.api import Api
    controller = Api('https://controller.community-lab.net/api/')
    slivers = controller.slivers.retrieve()
    slivers.retrieve_related('node', 'slice')
    
    # Calculate sliver MGMT IP according to CONFINE addressing specs
    # https://wiki.confine-project.eu/arch:addressing
    MGMT_IPV6_PREFIX = controller.testbed_params.mgmt_ipv6_prefix
    int_to_hex_str = lambda i,l: ('%.' + str(l) + 'x') % i
    split_by_len = lambda s,l: [s[i:i+l] for i in range(0, len(s), l)]
    for sliver in slivers.filter(slice__id=SLICE_ID):
        node_id = sliver.node.id
        slice_id = sliver.slice.id
        for iface in sliver.interfaces:
            if iface.type == 'management':
                nr = '10' + int_to_hex_str(iface.nr, 2)
                node_id = int_to_hex_str(node_id, 4)
                slice_id = int_to_hex_str(slice_id, 12)
                ipv6_words = MGMT_IPV6_PREFIX.split(':')[:3]
                ipv6_words.extend([node_id, nr])
                ipv6_words.extend(split_by_len(slice_id, 4))
                print ':'.join(ipv6_words)
                break


5. Pre-compile things on your own i686 virtual machine
At the time of writting this, common sliver free-space is arround ~700MB, which may be not enough for installing required dev libraries and compiling your average C++ application.
Moreover, doing so in an overcrowded Intel Atom machine will take like... I don't know, 10x more than in your high-end desktop?


6. Be prepared for network issues
Not all nodes have Internet connectivity, "apt-get install" will not always work
Network splits are common around CN. You may end-up having multiple isolated experiments rather than a single one.


7. Common development tools and network utils are missing :(
Add this to your "experiment.sh" and hope for Internet connectivity being available.
    apt-get update && \
    apt-get install -y inetutils-ping git traceroute tcpdump nano strace screen
You also can create your own sliver templates, but you'll have to learn a few things that you don't want to.


8. Did you forgot to set the slice state to start?
Me too :)
